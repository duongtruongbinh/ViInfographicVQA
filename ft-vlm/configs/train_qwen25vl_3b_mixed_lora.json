{
    "model_id": "Qwen/Qwen2.5-VL-3B-Instruct",
    "output_dir": "./outputs/qwen25vl_3b-mixed-lora",
    "max_train_samples": 256,
    "num_train_epochs": 1.0,
    "per_device_train_batch_size": 1,
    "gradient_accumulation_steps": 4,
    "learning_rate": 0.0002,
    "lr_scheduler_type": "linear",
    "warmup_ratio": 0.03,
    "logging_steps": 5,
    "save_steps": 200,
    "save_total_limit": 1,
    "bf16": false,
    "gradient_checkpointing": true,
    "dataset_name": "mixed",
    "single_dump_dir": "src/ft_vlm/dataset/dump_single_image",
    "multi_dump_dir": "src/ft_vlm/dataset/dump_multi_image",
    "images_base_dir": "",
    "single_sample_size": 128,
    "multi_sample_size": 128,
    "mixed_single_ratio": 0.5,
    "use_qlora": true,
    "lora_r": 16,
    "lora_alpha": 32,
    "lora_dropout": 0.05
}